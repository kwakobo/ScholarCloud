[{"title":"title","authors":"authors","article":"testdocument.txt","bibtex":"bibtex","text":"AMNESIA: Analysis and Monitoring\nfor NEutralizing SQL\u00c2\u00adInjection Attacks\nWilliam G.J. Halfond and Alessandro Orso College of Computing\nGeorgia Institute of Technology\n{ whalfond|orso }@cc.gatech.edu\nABSTRACT \nThe use of web applications has become increasingly popular in \nour routine activities, such as reading the news, paying bills, and \nshopping on-line. As the availability of these services grows, we \nare witnessing an increase in the number and sophistication of at-\ntacks that target them. In particular, SQL injection, a class of code- \ninjection attacks in which specially crafted input strings result in \nillegal queries to a database, has become one of the most serious\nthreats to web applications. In this paper we present and evalu- \nate a new technique for detecting and preventing SQL injection at- \ntacks. Our technique uses a model-based approach to detect illegal\nqueries before they are executed on the database. In its static part, \nthe technique uses program analysis to automatically build a model \nof the legitimate queries that could be generated by the applica-\ntion. In its dynamic part, the technique uses runtime monitoring to\ninspect the dynamically-generated queries and check them against \nthe statically-built model. We developed a tool, AM NE S I A, that \nimplements our technique and used the tool to evaluate the tech-\nnique on seven web applications. In the evaluation we targeted \nthe subject applications with a large number of both legitimate and \nmalicious inputs and measured how many attacks our technique de-\ntected and prevented. The results of the study show that our tech- \nnique was able to stop all of the attempted attacks without generat- \ning any false positives. \nCategories and Subject Descriptors: D.2.5 [Software Engineer-\ning]: Testing and Debugging\u00e2\u0080\u0094 Monitors;\nGeneral Terms: Security, Veri\u0002cation\nKeywords: SQL injection, static analysis, runtime monitoring\n1. INTRODUCTION Many organizations have a need to store sensitive information,\nsuch as customer records or private documents, and make this infor- \nmation available over the network. For this reason, database-driven\nweb applications have become widely deployed in enterprise sys- \ntems and on the Internet. Along with their growing deployment, \nthere has been a surge in attacks that target these applications. One \nPermission to make digital or hard copies of all or part of this w ork for\npersonal or classroom use is granted without fee provided th at copies are\nnot made or distributed for pro\u0002t or commercial advantage and th at copies\nbear this notice and the full citation on the \u0002rst page. To cop y otherwise, to\nrepublish, to post on servers or to redistribute to lists, re quires prior speci\u0002c\npermission and\/or a fee. \nASE'05, November 7\u00e2\u0080\u009311, 2005, Long Beach, California, USA.\nCopyright 2005 ACM 1\u00c2\u00ad58113\u00c2\u00ad993\u00c2\u00ad4\/05\/0011 ... $5.00. type of attack in particular,\nSQL Injection Attacks (SQLIA s), is es-\npecially harmful. SQLIAs can give attackers direct access to the \ndatabase underlying an application and allow them to leak con- \n\u0002dential, or even sensitive, information. There are many exam-\nples of SQLIAs with serious consequences, and the list of victims \nof such attacks includes high-pro\u0002le companies and associations, \nsuch as Travelocity, FTD.com, Creditcards.com, Tower Records,\nand RIAA. Even more alarming is a study performed by the Gart-\nner Group on over 300 web sites, which found that 97% of the sites \naudited were vulnerable to this kind of web attack. In fact, SQLIAs \nhave been described as one of the most serious security threats to\nweb applications [2, 21].\nSQL injection refers to a class of code-injection attacks in which\ndata provided by the user is included in a SQL query in such a way\nthat part of the user's input is treated as SQL code. SQLIAs are a \ntype of vulnerability that is ultimately caused by insuf\u0002cient input \nvalidation\u00e2\u0080\u0094they occur when data provided by the user is not prop-\nerly validated and is included directly in a SQL query. By lever- \naging these vulnerabilities, an attacker can submit SQL commands \ndirectly to the database. This kind of vulnerability represents a se-\nrious threat to any web application that reads input from the users \n(e.g., through web forms or web APIs) and uses it to make SQL \nqueries to an underlying database. Most web applications used on\nthe Internet or within enterprises work this way and could therefore\nbe vulnerable to SQL injection.\nAlthough the vulnerabilities that lead to SQLIAs are well un-\nderstood, they persist because of a lack of effective techniques for\ndetecting and preventing them. Programming practices such as de- \nfensive programming and sophisticated input validation techniques \ncan prevent some vulnerabilities. However, attackers continue to\n\u0002nd new exploits that can avoid the checks programmers put in \nplace (e.g., [16, 19, 24]). Moreover, defensive programming is \nlabor-intensive, which makes it an impractical technique for pro-\ntecting large legacy systems. General tools such as \u0002rewalls and \ncurrent Intrusion Detection Systems (IDSs) are also typically in- \neffective against SQLIAs\u00e2\u0080\u0094SQLIAs are performed through ports\nused for regular web traf\u0002c (usually open in \u0002rewalls) and work at\nthe application level (unlike most IDSs). Finally, most analysis- \nbased techniques for vulnerability detection do not address the spe- \nci\u0002c characteristics of SQLIAs and are thus ineffective in this con-\ntext. The few analysis techniques speci\u0002cally designed to target \nSQLIAs provide only partial solutions to the problem. In particular, \ndynamic techniques, such as penetration testing, introduce issues\nof completeness and often result in false negatives being produced, \nwhereas techniques based on static analysis are either too imprecise \nor only focus on a speci\u0002c aspect of the problem.  \n 174\n\nIn this paper, we propose a novel technique to counter SQLIAs.1\nOur technique builds upon work done in model-based security and \nin program analysis and uses a combination of static and dynamic\nanalysis techniques that is speci\u0002cally designed to target SQLIAs. \nThe key insights behind the development of the technique are that \n(1) the information needed to predict the possible structure of the\nqueries generated by a web application is contained within the ap- \nplication's code, and (2) an SQLIA, by injecting additional SQL \nstatements into a query, would violate that structure. Therefore, our\ntechnique \u0002rst uses static program analysis to analyze the applica- \ntion code and automatically build a model of the legitimate queries \nthat could be generated by the application. Then, at runtime, the\ntechnique monitors all dynamically-generated queries and checks \nthem for compliance with the statically-generated model. Queries \nthat violate the model are classi\u0002ed as illegal, prevented from exe-\ncuting on the database, and reported to the application developers\nand administrators. In the paper, we also present an empirical evaluation of the tech-\nnique. We implemented the technique in a prototype tool, AM NE -\nS I A, and used the tool to evaluate the technique on a set of seven\nsubjects of various types and sizes. We targeted the subjects with a\nlarge number of both legitimate accesses and SQL-injection attacks\nand assessed the ability of our technique to detect and prevent the \nattacks without stopping any legitimate access to the database. The \nresults of the evaluation are very promising. AM NE S I A was able\nto stop all of the 1,470 attacks without generating any false positive \nfor the 3,500 legitimate accesses. Moreover, our technique proved \nto be very ef\u0002cient, in that it imposed a negligible overhead on the\nsubject web applications. The main contributions of this work are:\n\u00e2\u0080\u00a2 The presentation of a new technique to counter SQL-injection\nattacks that combines static analysis and runtime monitoring.\n\u00e2\u0080\u00a2 A tool, AM NE S I A, that implements the technique for Java-\nbased web applications.\n\u00e2\u0080\u00a2 An empirical evaluation of the technique that shows the ef-\nfectiveness and the ef\u0002ciency of the technique.\n\u00e2\u0080\u00a2 The development of a test bed for the evaluation of web-\napplication protection techniques that can be reused by other \nresearchers.\nThe rest of this paper is organized as follows. In Section 2 we\nreview and discuss related work. We provide an example of an \nSQLIA in Section 3 and discuss our technique in Section 4. We\nexamine additional considerations in Section 5. Section 6 presents \nour empirical evaluation and, \u0002nally, we conclude and outline fu- \nture work in Section 7. \n2. RELATED WORK\nMany existing techniques, such as \u0002ltering, information-\u0003ow anal-\nysis, penetration testing, and defensive coding, can detect and pre- \nvent a subset of the vulnerabilities that lead to SQLIAs. In this\nsection, we list the most relevant techniques and discuss their limi-\ntations with relation to SQLIAs. \nDefensive Programming. Developers have employed a range\nof code-based solutions to counter SQLIAs. Input validation based \ntechniques include checking user input for keywords, identifying \nknown malicious patterns, and escaping potentially troublesome\ncharacters. While these techniques can stop straightforward and\n1 An early version of this work is described in a paper presented at\nWODA 2005 [10]. unsophisticated attacks, attackers have learned to use alternate en- \ncoding schemes such as hexadecimal, ASCII and Unicode to ob-\nfuscate their attacks. Furthermore, simply checking user input for\nmalicious keywords would clearly result in a high rate of false pos- \nitives, since an input \u0002eld could legally contain words that match \nSQL keywords (i.e. \u00e2\u0080\u009cFROM\u00e2\u0080\u009d, \u00e2\u0080\u009cOR\u00e2\u0080\u009d, \u00e2\u0080\u009cAND\u00e2\u0080\u009d). Another widely pro-\nposed coding solution is to use stored procedures for database ac- \ncess. The ability of stored procedures to prevent SQLIAs is depen- \ndent on its implementation. The mere fact of using stored proce-\ndures does not protect against SQLIA. Interested readers may ref\ner\nto [1, 11] for examples of how applications that use stored proce-\ndures, escaping of characters, and different forms of input valida -\ntion can be vulnerable to SQLIAs.\nTwo recent approaches, SQL DOM [18] and Safe Query Ob-\njects [6], use encapsulation of database queries to provide a safe\nand reliable way to access databases. These techniques offer an\neffective way to avoid the SQLIA problem by changing the query- \nbuilding process from an unregulated one that uses string concate- \nnation to a systematic one that uses a type-checked API. (In this\nsense, SQL DOM and Safe Query Objects can be considered in- \nstances of defensive coding.) Although effective, these techniques \nhave the drawback that they require developers to learn and use a\nnew programming paradigm or query-development process, unlike \nour technique. In general, defensive coding has not been successful in com-\npletely preventing SQLIA (e.g., [16, 19, 24]). Attackers keep \u0002nd-\ning new attack strings or subtle variations on old attacks that can \navoid the checks programmers put in place. While improved cod-\ning practices (e.g., [11]) can help mitigate the problem, they are\nlimited by the developer's ability to generate appropriate input val- \nidation code and recognize all situations in which it is needed. Our \napproach, being fully automated, can provide stronger guarantees\nabout the completeness and accuracy of the protections put in place. \nGeneral Techniques Against SQLIAs. Other researchers\nhave developed techniques speci\u0002cally targeted at SQLIAs. Scott \nand Sharp [23] use a proxy to \u0002lter input and output data streams \nfor a web application based on policy rules de\u0002ned at the enterprise\nlevel. Although this technique can be effective against SQLIA, it \nrequires developers to correctly specify \u0002ltering rules for each ap- \nplication input. This step of the process is prone to human-error\nand leaves the application vulnerable if the developer has not ad- \nequately identi\u0002ed all injection points and correctly expressed the \n\u0002ltering rules. Like defensive coding practices, this technique can-\nnot provide guarantees of completeness and accuracy. Huang and colleagues [12] propose WAVE S, a black-box tech-\nnique for testing web applications for SQL-injection vulnerabili-\nties. This technique improves over general penetration-testing tech-\nniques by using machine learning to guide its testing, but like all \nblack-box testing techniques, it cannot provide guarantees of com- \npleteness that static analysis based techniques are able to provide. Boyd and colleagues propose SQLrand, an approach based on\nrandomization of SQL instructions using a key [3], which extends\na previous approach to counter general code-injections attacks [14].\nIn this approach, SQL code injected by an attacker would result in \na syntactically incorrect query. Although effective, this technique \ncould be circumvented if the key used for the randomization were\nexposed. Moreover, the approach imposes a signi\u0002cant overhead\nin terms of infrastructure because it requires the integration of a \nspecial proxy in the web-application infrastructure. Two related approaches by Nguyen-Tuong and colleagues [20]\nand Pietraszek and Berghe [22] modify the PHP interpreter to track\nprecise taint information about user input. The techniques use a  \n 175\n\ncontext sensitive analysis to detect and reject queries if untrusted \ninput has been used to create certain types of SQL tokens.Valeur and colleagues [25] propose the use of an Intrusion De-\ntection System (IDS) to detect SQLIA. Their IDS system is based \non a machine learning technique that is trained using a set of typ- \nical application queries. The technique builds models of the typi-\ncal queries and then monitors the application at runtime to identify \nqueries that do not match the model. Overall, this technique uses \nan approach similar to ours, in that it builds expected query mod-\nels and then checks dynamically-generated queries for compliance \nwith the model. Their technique, however, like most techniques \nbased on learning, can generate large number of false positive in\nthe absence of an optimal training set. \nStatic Analysis Techniques. The Java String Analysis (JSA)\nlibrary, developed by Christensen, M\u00c3\u00b8ller, and Schwartzbach [5] \nprovides us with a mechanism for generating models of Java strings. \nJSA performs a conservative string analysis of an application and\ncreates automata that express all the possible values a speci\u0002c string\ncan have at a given point in the application. Although this tech- \nnique is not directly related to SQLIA, it is important to our work \nbecause we use the library to generate intermediate forms of of our\nSQL-query models. Other works such as JDBC-Checker [7, 8], \nalso make use of this library in their analysis.\nJDBC-Checker is a technique for statically checking the type\ncorrectness of dynamically-generated SQL queries by Gould, Su,\nand Devanbu [7, 8]. This technique was not intended to detect and \nprevent general SQLIAs, but can nevertheless be used to prevent\nattacks that take advantage of type mismatches in a dynamically \ngenerated query string to crash the underlying database. JDBC- \nChecker is able to detect one of the root causes of SQLIA vulner-\nabilities in code, which is improper type checking of input. How-\never, this technique would not catch more general forms of SQLIAs \nbecause these attacks must generate syntactically and type correct \nqueries in order to be successful. This technique also relies on the\nJSA [5] library, and we use a similar approach to build an interme- \ndiate form of our SQL-query models (see Section 4.2). Wassermann and Su propose an approach that uses static analysis\ncombined with automated reasoning to verify that the SQL queries\ngenerated in the application layer cannot contain a tautology [26]. \nThe primary drawback of this technique is that it is limited to only\ndetecting and preventing tautologies, which is only one of the many \nkinds of SQLIAs that our technique addresses. Huang and colleagues also de\u0002ne a white-box approach for de-\ntecting input validation related errors that uses developer-provided \nannotations [13]. Relying on developer-provided annotations lim- \nits the practical applicability of the approach and the technique as- \nsumes that preconditions for all sensitive functions can be accu-\nrately expressed ahead of time, which is not always the case. Our \ntechnique is fully automated and does not require any developer in- \ntervention, such as annotations, in order to protect the application. Recent work by Livshits and Lam [15] uses static analysis tech-\nniques to detect vulnerabilities that have been described using the\nPQL language [17]. In this approach, vulnerability signatures are\ndescribed using PQL, and a static analyzer is generated from the \nvulnerability description. The analyzer detects instances of the vul- \nnerability in the code. As opposed to our technique, this approach\nattempts to \u0002nd known SQLIAs vulnerabilities in code as opposed\nto preventing them dynamically. Therefore, the approach can be ef- \nfective in improving the code base of an application by identifying \nvulnerabilities in the program that can then be eliminated. How-\never, the approach is limited, in that it can only detect known and \nspeci\u0002ed vulnerabilities. 3. SQL INJECTION ATTACKS\nBefore describing our approach, we introduce a simple example\nof an SQL Injection Attack (SQLIA). This will be used as a running \nexample throughout the paper as we describe our technique. We \nprovide a more rigorous de\u0002nition of SQLIAs in Section 3.2. \n3.1 Example of SQL\u00c2\u00adInjection Attack\nIn this section we introduce an example of a web application that\nis vulnerable to an SQLIA and explain how an attacker could ex- \nploit this vulnerability. This particular example illustrates an attack\nbased on injecting a tautology into the query string. Although tau- \ntologies represent only a subset of the SQLIAs that our technique \ncan address, we use this type of attack for illustration because it is\nstraightforward to understand and does not require deep knowledge \nof SQL syntax and semantics. Figure 1 shows a typical web application in which a user on\na client machine can access services provided by an application\nserver and an underlying database. When the user enters a login \nand a password in the web form and presses the submitbut-\nton, a URL is generated ( http:\/\/foo.com\/show.jsp?login=\ndoe&pass=xyz ) and sent to the web server. The \u0002gure illustrates\nwhich components of the web application handle the different parts\nof the URL. In the example, the user input is interpreted by servlet show.jsp.\n(Servlets are Java applications that operate in conjunction with a\nWeb server.) In this scenario the servlet would (1) use the user\ninput to build a dynamic SQL query, (2) submit the query to the \ndatabase, and (3) use the response from the database to generate \nHTML-pages that are then sent back to the user. Figure 2 shows\nan excerpt of a possible implementation of servlet show.jsp.\nMethod getUserInfo is called with the login and the password\nprovided by the user. If both loginandpassword are empty,\nthe method submits the following query to the database: \nSELECT info FROM users WHERE login='guest'\nIf login andpassword are de\u0002ned by the user, the method em-\nbeds the submitted credentials in the query. Therefore, if a user \nsubmits loginandpassword as \u00e2\u0080\u009cdoe \u00e2\u0080\u009d and \u00e2\u0080\u009c xyz,\u00e2\u0080\u009d the servlet\ndynamically builds the query: \nSELECT info FROM users WHERE login='doe' AND pass='xyz'\nA web site that uses this servlet would be vulnerable to SQLIAs. \nFor example, if a user enters \u00e2\u0080\u009c ' OR 1=1 --\u00e2\u0080\u009d and \u00e2\u0080\u009c\u00e2\u0080\u009d, instead of\n\u00e2\u0080\u009c doe \u00e2\u0080\u009d and \u00e2\u0080\u009c xyz\u00e2\u0080\u009d, the resulting query is:\nSELECT info FROM users WHERE login='' OR 1=1 --' AND pass='' \nThe database interprets everything after the WHERE token as a \nconditional statement, and the inclusion of the \u00e2\u0080\u009c OR 1=1\u00e2\u0080\u009d clause\nturns this conditional into a tautology. (The characters \u00e2\u0080\u009c --\u00e2\u0080\u009d mark\nthe beginning of a comment, so everything after them is ignored.)\nAs a result, the database would return information about all users. \nAn attacker could insert a wide range of SQL commands via this \nexploit. \n3.2 De\u0002nition of SQL\u00c2\u00adInjection Attack\nAn SQL Injection Attack (SQLIA) occurs when an attacker at-\ntempts to change the logic, semantics or syntax of a legitimate \nSQL statement by inserting new SQL keywords or operators into \nthe statement. This broad de\u0002nition includes all of the variants of SQLIA re-\nported in Anley's extensive documentation [1]. In particular, the\nde\u0002nition includes, but is not limited to, attacks based on tautolo-\ngies, injected additional statements, exploiting untyped parame-  \n 176\n\nFigure 1: Example of interaction between a user and a typical web application.\nters, stored procedures, overly descriptive error messages, alter -\nnate encodings, length limits, second-order injections and injection \nof \u00e2\u0080\u009dUNION SELECT\u00e2\u0080\u009d, \u00e2\u0080\u009dORDER BY\u00e2\u0080\u009d, and \u00e2\u0080\u009dHAVING\u00e2\u0080\u009d clauses. \n(See [1] for a detailed explanations of the different types and forms\nof SQLIA.) \n4. PROPOSED SOLUTION\nOur proposed solution is a general technique that addresses all\ntypes of SQLIAs as de\u0002ned in Section 3.2. The approach works \nby combining static analysis and runtime monitoring. The key in- \ntuition behind the approach is that (1) the source code contains \nenough information to infer models of the expected, legitimate SQL\nqueries generated by the application, and (2) an SQLIA, by inject- \ning additional SQL statements into a query, would violate such a \nmodel. In its static part, our technique uses program analysis to\nautomatically build a model of the legitimate queries that could be\ngenerated by the application. In its dynamic part, our technique \nmonitors the dynamically generated queries at runtime and checks \nthem for compliance with the statically-generated model. Queries\nthat violate the model represent potential SQLIAs and are thus pre- \nvented from executing on the database and reported. The technique consists of four main steps. We summarize the\nsteps and then describe them in more detail in subsequent sections. \nIdentify hotspots: Scan the application code to identify hotspots\u00e2\u0080\u0094\npoints in the application code that issue SQL queries to the \nunderlying database.\nBuild SQL-query models: For each hotspot, build a model that\nrepresents all the possible SQL queries that may be generated \nat that hotspot. A SQL-query modelis a non-deterministic\n\u0002nite-state automaton in which the transition labels consist \nof SQL tokens (SQL keywords and operators), delimiters, \nand place holders for string values.\nInstrument Application: At each hotspot in the application, add\ncalls to the runtime monitor.\nRuntime monitoring: At runtime, check the dynamically-generated\nqueries against the SQL-query model and reject and report \nqueries that violate the model.\n4.1 Identify Hotspots This step performs a simple scanning of the application code\nto identify hotspots. For the example servlet in Figure 2, the set \nof hotspots would contain a single element: the statement at line \n10. (In Java-based applications, interactions with the database oc-\ncur through calls to speci\u0002c methods in the JDBC library, 2\nsuch as\njava.sql.Statement.execute(String) .)\n2\nhttp:\/\/java.sun.com\/products\/jdbc\/ public class Show extends HttpServlet {\n...\n1. public ResultSet getUserInfo(String login, String password) {\n2. Connection conn = DriverManager.getConnection(\"MyDB\" );\n3. Statement stmt = conn.createStatement(); \n4. String queryString = \"\"; \n5. queryString = \"SELECT info FROM userTable WHERE \"; \n6. if ((! login.equals(\"\")) && (! password.equals(\"\"))) { \n7. queryString += \"login='\" + login +\n\"' AND pass='\" + password + \"'\";\n}\n8. else {\n9. queryString+=\"login='guest'\"; }\n10. ResultSet tempSet = stmt.execute(queryString);\n11. return tempSet; }\n...\n}\nFigure 2: Example servlet.\n4.2 Build SQL\u00c2\u00adQuery Models In this step we build the SQL-query model for each hotspot iden-\nti\u0002ed in the previous step. Within each hotspot, we are interested \nin computing the possible values of the query string passed to the \ndatabase. To do this, we use the Java String Analysis (JSA) [5] li- \nbrary. This technique constructs a \u0003ow graph that abstracts away\nthe control \u0003ow of the program and represents string-manipulation \noperations performed on string variables. For each string of inter- \nest the technique analyzes the \u0003ow graph and simulates the string-\nmanipulation operations that are performed on the string. The re- \nsult of the analysis is a Non-Deterministic Finite Automaton (NDFA) \nthat expresses, at the character level, all the possible values the con-\nsidered string can assume. The string analysis is conservative, so\nthe NDFA for a string is an overestimate of all the possible values \nof the string. It is worth noting that the JSA [5] technique generates Deter-\nministic Finite Automata (DFAs), obtained by transforming each\nNDFA into a corresponding DFA. However, the transformation to \nDFAs increases the number of states and transitions in the graph\nand introduces cycles that complicate the construction of our SQL- \nquery model. Therefore, we use their technique but skip its last \nstep. To build our SQL-query model for a given hotspot, we use the\nfollowing process. We perform a depth \u0002rst traversal of the NDFA\nfor the hotspot and group characters as either SQL keywords, op-\nerators, or literal values and create a transition in the SQL-query  \n 177\n\nmodel that is annotated with their literal value. For example, a se- \nquence of transitions labeled 'S', 'E', 'L', 'E', 'C', and 'T' would\nbe recognized as the SQLSELECTkeyword and suitably grouped\ninto a single transition labeled \u00e2\u0080\u009cSELECT\u00e2\u0080\u009d. Because there are sev- \neral SQL dialects each with their own set of keywords and oper- \nators, this part of the technique can be customized to recognize\ndifferent dialects. We represent variable strings(i.e., strings that\ncorrespond to a variable related to some user input) using the sym-\nbol \u0000(e.g., in our example the value of the variable passwordis\nrepresented as \u0000.). This process is analogous to the one used by\nGould, Su, and Devanbu [8], except that we perform it on NDFAs\ninstead of DFAs. Figure 3 shows the SQL-query model for the single hotspot in\nour example. The model re\u0003ects the two different query strings\nthat can be generated by the code depending on the branch followed\nafter the ifstatement at line 6 (Figure 2).\n4.3 Instrument Application In this step, we instrument the application by adding calls to\nthe monitor that check the queries at runtime. For each hotspot,\nthe technique inserts a call to the monitor before the call to the \ndatabase. The monitor is invoked with two parameters: the string \nthat contains the actual query about to be submitted and a unique\nidenti\u0002er for the hotspot. Using the unique identi\u0002er, the runtime \nmonitor is able to correlate the hotspot with the speci\u0002c SQL-query \nmodel that was statically generated for that point and check the\nquery against the correct model. Figure 4 shows how the example application would be instru-\nmented by our technique. The hotspot, originally at line 10 in Fig-\nure 2, is now guarded by a call to the monitor at line 10a.\n... \n10a. if (monitor.accepts ( <hotspot ID >,\nqueryString))\n{\n10b. ResultSet tempSet = stmt.execute(queryString);\n11. return tempSet;\n}\n...\nFigure 4: Example hotspot after instrumentation.\n4.4 Runtime Monitoring At runtime, the application executes normally until it reaches a\nhotspot. At this point, the string that is about to be submitted as a \nquery is sent to the runtime monitor. The monitor parses the query \nstring into a sequence of tokens according to the speci\u0002c SQL syn- \ntax considered. Tokens in the query that represent string or numeric\nconstants can match any transition in the SQL-query model labeled\nwith \u0000. Note that, in our parsing of the query string, the parser\nidenti\u0002es empty string constants by their syntactic position and we\ndenote these in the parsed query string using \u0000, the common sym-\nbol for the empty string. Figure 5 shows how the last two queries \ndiscussed in Section 3.1 would be parsed during runtime monitor- \ning. It is important to point out that our technique parses the query\nstring the same way that the database would, according to the spe-\nci\u0002c SQL grammar considered. In other words, it does not do a\nsimple keyword matching over the query string, which would cause \nfalse positives and problems with user input that happened to match \nSQL keywords. For example, a user-submitted string that contains\nSQL keywords but is syntactically a text \u0002eld, would be correctly recognized as a text \u0002eld. However, if the user were to inject special\ncharacters, as in our example, to force part of the text to be eval-\nuated as a keyword, the parser would correctly interpret this input\nas a keyword. Using the same parser as the database is important \nbecause it guarantees that we are interpreting the query the same \nway that the database will.\nAfter the query has been parsed, the runtime monitor checks it\nby assessing whether the query violates the SQL-query model as-\nsociated with the hotspot from which the monitor has been called.\nAn SQL-query model is an NDFA whose alphabet consists of SQL \nkeywords, operators, literal values, and delimiters, plus the spe- \ncial symbol \u0000. Therefore, to check whether a query is compliant\nwith the model, the runtime monitor can simply check whether the \nmodel (i.e., the automaton) accepts the query (i.e., whether a se- \nries of valid transitions reaches an accepting state). Recall that\na string constant (including \u0000) or numeric constant in the parsed\nquery string can match either \u0000or an identical literal value in the\nSQL-query model. If the model accepts the query, then the monitor lets the execu-\ntion of the query continue. Otherwise, the monitor identi\u0002es the \nquery as an SQLIA. In this case, the monitor prevents the query \nfrom executing on the database and reports the attack. To illustrate, consider again the queries from Section 3.1 shown\nin Figure 5 and recall that the \u0002rst query is legitimate, whereas the\nsecond one corresponds to an SQLIA. When checking query (a ),\nthe analysis would start matching from token\nSELECTand from\nthe initial state of the SQL-query model in Figure 3. Because the to- \nken matches the label of the only transition from the initial state, the \nautomaton reaches the second state. Again, token\ninfomatches\nthe only transition from the current state, so the automaton reaches \nthe third state. The automaton continues to reach new states until \nit reaches the state whose two outgoing transitions are labeled \u00e2\u0080\u009c =\u00e2\u0080\u009d.\nAt this point, the automaton would proceed along both transitions. \nOn the upper branch, the query is not accepted because the automa- \nton does not reach an accept state. Conversely, on the lower branch, \nall the tokens in the query are matched with labels on transitions,\nand the automaton reaches the accept state after consuming the last \ntoken in the query (\u00e2\u0080\u009c '\u00e2\u0080\u009d). The monitor can therefore conclude that\nthis query is legitimate. The checking of query (b ) proceeds in an analogous way until\ntoken\nORin the query is reached. Because the token does not\nmatch the label of the only outgoing transition from the current \nstate ( AND), the query is not accepted by the automaton, and the\nmonitor identi\u0002es the query as an SQLIA.\nOnce an SQLIA has been detected, our technique stops the query\nbefore it is executed on the database and reports relevant informa-\ntion about the attack in a way that can be leveraged by developers. \nIn our implementation of the technique for Java, we throw an ex- \nception when the attack is detected and encode information about\nthe attack in the exception. If developers want to access the infor- \nmation at runtime, they can simply leverage the exception-handling \nmechanism of the language and integrate their handling code into\nthe application. Having this attack information available at runtime is useful be-\ncause it allows developers to react to an attack right after it is de-\ntected and develop an appropriate customized response. For exam-\nple, developers may decide to avoid any risk and shut-down the part \nof the application involved in the attack. Alternatively, a developer \ncould handle the attack by converting the information into a for-\nmat that is usable by another tool, such as an Intrusion Detection \nSystem, and reporting it to that tool. Because this mechanism inte- \ngrates with the application's language, it allows developers a good\ndeal of \u0003exibility in choosing a response to SQLIAs.  \nFigure 3: Example hotspot after instrumentation.\n\nin fo\nS ELE C TFR O M use rT a bleW HER E\n=guest\n=\n&#39;\n&#39;\n\u00ce\u00b2&#39;&#39;AN D p\nass= \u00ce\u00b2&#39;&#39;\nlo g\nin\nlo g\nin\nFigure 3: SQL-query model for the servlet in Figure 2.\n(a) SELECT info FROM users WHERE login='doe' AND pass='xyz'\nSELECTinfoFROMusersWHERElogin='doe'ANDpass='xyz'\n(b) SELECT info FROM users WHERE login='' OR 1=1 -- 'AND pass= ''\nSELECTinfoFROMusersWHERElogin='\u0000'OR1=1--'ANDpass='\u0000'\nFigure 5: Example of parsed runtime queries.\nCurrently, the information reported by our technique includes the\ntime of the attack, the location of the hotspot that was exploited, \nthe attempted-attack query, and the part of the query that was not\nmatched against the model. We are currently considering additional \ninformation that could be useful for the developer (e.g., information \ncorrelating program execution paths with speci\u0002c parts of the query\nmodel) and investigating ways in which we can modify the static \nanalysis to collect this information. \n5. ADDITIONAL CONSIDERATIONS \n5.1 Ef\u0002ciency\nIn terms of ef\u0002ciency, our approach requires the execution of the\nmonitor for each database query. Since we check the query against \nthe SQL-query model, which is an NDFA, the worst case complex- \nity is exponential in the size of the automaton, which in the worst\ncase is quadratic in the size of the program [5]. However, the visit\nof the NDFA is typically linear because the automata generated by \nthe analysis are usually trees. Also, the automata are linear for \ntypical programs\u00e2\u0080\u0094the case of a quadratic size corresponds to an\napplication that modi\u0002es the query string and branches in each line \nof the program. In fact, our experience is that most automata are \nactually quite small with respect to the size of the corresponding\napplication. In practice, considered that the monitor just checks a \ntypically short set of tokens against an NDFA, whereas database \nqueries normally involve interactions over a network, we expect\nthe overhead for the monitoring to be negligible. This intuition is \ncon\u0002rmed by our empirical evaluation (see Section 6). \n5.2 Effectiveness and Precision\nOur technique can produce false negatives in two situations: (1)\nwhen the string analysis results in a SQL query model that is overly \nconservative and includes spurious queries (i.e. queries that could\nnot be generated by the application) that happen to match an at- \ntack; and (2) when a legitimate query happens to have the same \n\u00e2\u0080\u009cSQL structure\u00e2\u0080\u009d of an attack. For example, if a developer adds\nconditions to a query from within a loop, an attacker who inserts an \nadditional condition of the same type would generate a query that \ndoes not violate the SQL-query model. We expect both of these\ncases to be rare in practice because of the typically peculiar struc- \nture of SQLIAs. The attacker would have to produce an attack that \ndirectly matches either an imprecision of the analysis or a speci\u0002c\npattern. Moreover, in both cases, the type of attacks that could be exploited would be limited by the constraints imposed by the rest\nof the model that was used to match the query.\nAlthough the string analysis that we use is conservative, there are\nsituations in which our technique can produce false positives. False \npositives can occur when the string analysis is unable to generate \na string model that is precise enough. In particular, if the string\nanalysis over-approximates a hard-coded string and this hard-coded \nstring is used in the application to construct a SQL token, our tech- \nnique will generate an incomplete SQL-query model. The prob-\nlem is that, in these cases, our analysis cannot determine whether \nthe over-approximation represents a variable or a hard-coded SQL \ntoken. Our analysis could either allow queries to partially match\nkeywords and variables (possibly causing false negatives) or reject \nqueries that traverse those particular transitions (possibly causing \nfalse positives). We chose a conservative approach and decided to\nreject the queries in these cases. It is worth noting that this situation\ndid not occur in any of the 271 automata that we generated for our \nevaluation. Lastly, it is important to note the scope of our technique. Our\ntechnique targets SQLIAs, which are exploits where an attacker\nis attempting to inject SQL statements into a query sent to the \ndatabase. SQLIAs do notinclude other types of web-application-\nrelated attacks. For example, a common attack on web applications \nis to steal authentication tokens that are passed between a browser \nand the database application to hijack the session and issue queries\nto the database. This is not an injection attack because the attacker \nis simply using the rights and privileges assigned to the victim to \naccess the database through legitimate (i.e., non injected) queries. \n5.3 Assumptions\nOur technique requires two assumptions to be satis\u0002ed by the\ntargeted web application. The \u0002rst assumption is that user input \nconsists only of values, such as numbers and strings, that are not \nmeant to be interpreted as SQL tokens. In other words, our tech-\nnique cannot handle cases in which the user input is legitimately \nsupposed to add SQL tokens to the query. Applications that allow \nthe user to do so would cause our technique to generate false posi-\ntives because we would recognize the user-introduced SQL tokens \nand operators as an injection. (While this is technically correct ac- \ncording to our de\u0002nition of SQLIA, because the user input is an\nactual injection of SQL tokens, blocking these queries would result \nin incorrect behavior for this type of application.) In general, this \nis a reasonable assumption. Users can still enter SQL statements\nin a \u0002eld (e.g., a text area of a discussion board on SQL), as long  \n Figure 4: SQL-query model for the servlet in Figure 2.\n\nas the application treats such input as text. Applications that do \nallow users to directly enter SQL queries are typically database-\nadministration tools whose usage is restricted to a trusted set of\nusers connecting from speci\u0002c machines.Second, we assume that application developers build database\nqueries by combining substrings and that they do not obfuscate the\nlogic of the query construction. This assumption is important be- \ncause our technique's safety and precision depends on the accuracy \nof the underlying string analysis, which in turn depends on the com-\nplexity of the query-generation code. Because of this assumption, \nour technique cannot handle applications that use different query- \ndevelopment paradigms, such as SQL DOM [18], and applications\nthat store query strings in a way that prevents the string analysis \nfrom detecting them (e.g., in a \u0002le). We believe that this assump- \ntion is not too restrictive. In fact, it is satis\u0002ed by all of the web\napplications that we have analyzed so far. Also, the same assump-\ntion has been widely adopted by other researchers [1, 3, 5, 7, 8, 11, \n12, 13, 16, 19, 20, 21, 22, 24, 26]. \n6. EVALUATION\nThe goal of our empirical evaluation is to assess the effectiveness\nand ef\u0002ciency of the technique presented in this paper when applied \nto various web applications. We developed a prototype tool, called\nAM NE S I A, that implements the technique, and used it to perform\nan empirical study on a set of subjects. The study investigates three\nresearch questions: RQ1: What percentage of attacks can our technique detect and\nprevent that would otherwise go undetected and reach the database? RQ2: How much overhead does our technique impose on web\napplications at runtime?\nRQ3: What percentage of legitimate accesses does our tech-\nnique identify as false positives?\nThe following sections present the tool, illustrate the setup for\nour evaluation, and discuss the two studies that we performed to\naddress our research questions. \n6.1 The Tool: AM NE S I A\nAM NE S I A (Analysis and Monitoring for NEutralizing SQL In-\njection Attacks) is the prototype tool that implements our technique \nto counter SQLIAs for Java-based web applications. AM NE S I A is \ndeveloped in Java and its implementation consists of three modules \nthat leverage various existing technologies and libraries: \nAnalysis module. This module implements Steps 1 and 2 of our\ntechnique. Its input is a Java web application and it out- \nputs a list of hotspots and a SQL-query models for each\nhotspot. For the implementation of this module, we lever- \naged JSA [5]. The analysis module is able to analyze Java \nServlets as well as JSP pages.\nInstrumentation module. This module implements Step 3 of our\ntechnique. It inputs a Java web application and a list of\nhotspots and instruments each hotspot with a call to the run- \ntime monitor. We implemented this module using I N SE C T,\na generic instrumentation and monitoring framework for Java \ndeveloped at Georgia Tech [4].\nRuntime-monitoring module. This module implements Step 4 of\nour technique. It takes as input a query string and the ID\nof the hotspot that generated the query, retrieves the SQL- \nquery model for that hotspot, and checks the query against \nthe model. For this module, we also leveraged I N SE C T.\nFigure 6 shows a high-level overview of AM NE S I A. In the\nstatic phase, the Instrumentation Module and the Analysis Module\ntake as input a web application and produce (1) an instrumented\nW eb\nA\nppl i c at i o n\nI nst r um ent a t i o n\nM\nodul e\nA nal y si s\nM\nod ul e\nR unt i m e\nM\noni t o ri n g\nM\nodul e\nI n st r um ent e d\nW\neb\nA\nppl i c at i o n\nSQ L9Q u\ne ry\nM\nodel\nI n st r um ent e d\nW\neb\nA\nppl i c at i o n\nD\nat a base\nR epo rt\nA MNESI A To o l set\nUse r s\nBr o wse r\/\nA\npp l i c ati o n\nURL\nHT M L\/\nD\nat a\nMal i c i ous Q ue r y\nL\ne g i ti m at e Que r y\nD\nat a\nS ta ti c Pha se\n(\nS\nta ti c Ana l y si s )\nD\ny na m i c Pha se\n(\nR un\ntim e Mo ni to rin g )\nFigure 6: High-level overview of AMNE S I A.\nversion of the application, and (2) an SQL-query model for each \nhotspot in the application. In the dynamic phase, the Runtime- \nMonitoring Module checks the dynamic queries while users inter-\nact with the web application. If a query is identi\u0002ed as an attack, it \nis blocked and reported. \n6.2 Experiment Setup To be able to investigate our research questions, we needed a test\nbed for our technique and tool. In particular, we needed a set of web \napplications and a set of inputs for those applications that included\nboth legitimate inputs and SQLIAs. In the next two sections, we\npresent the subjects that we collected for our studies and describe \nhow we generated a large, meaningful set of inputs for the subjects. \nIn our experimental setup, we were careful to develop the test bed\nin a way that allows us (and other researchers) to easily rerun our \nexperiments.\n6.2.1 Subjects For the evaluation we used seven experimental subjects. The\nsubjects are all typical web applications that accept input from the \nuser through a web form and use the input to build queries to an un-\nderlying database. Five of the subjects, Employee Directory, Book- \nstore, Events, Classi\u0002eds, and Portal, are commercialapplications\nthat we obtained from GotoCode ( http:\/\/www.gotocode.\ncom ). The two remaining applications, Checkers and Of\u0002ce Talk,\nwere developed by different teams of students as part of a class \nproject. Although these last two are not commercial applications,\nwe selected them because they have been used in previous, related\nstudies [8]. All subjects were deployed on our local test bed servers \nas they would be in a commercial setting. Table 1 provides information about the subjects. For each sub-\nject, the table shows its name ( Subject); a concise description ( De-\nscription ); its size in terms of lines of code ( LOC); the number\nof accessible servlets ( Servlets) with the total number of servlets\nin the application in parenthesis; the number of injectable param-\neters ( Injectable Params ); the number of state parameters ( State\nParams ); the number of hotspots ( Hotspots); and the average size\nof the SQL automata generated by AM NE S I A ( Automata Size),\nwith the minimum\u00e2\u0080\u0093maximum range in parentheses. We de\u0002ne an injectable parameter as an input parameter to a\nweb application whose value is used to build part of a query that is      \n 180\n\nSubjectDescriptionLOCServletsInjectableStateHotspotsAutomata SizeParamsParamsSize (#nodes)CheckersOnline checkers game5,42118 (61)4405289 (2\u00e2\u0080\u0093772)Of\u0002ce TalkPurchase-order management system4,5437 (64)1314040 (8\u00e2\u0080\u0093167)Employee DirectoryOnline employee directory5,6587 (10)25923107 (2\u00e2\u0080\u0093952)BookstoreOnline bookstore16,9598 (28)36671159 (2\u00e2\u0080\u00935,269)EventsEvent tracking system7,2427 (13)36103177 (2\u00e2\u0080\u0093550)Classi\u0002edsOnline management system for classi\u0002eds10,9496 (14)1883491 (2\u00e2\u0080\u0093799)PortalPortal for a club16,4533 (28)39767117 (2\u00e2\u0080\u00931,187)\nTable 1: Subject programs for the empirical study.\nthen sent to the database. We de\u0002ne a state parameteras a param-\neter that may affect the \u0003ow of control within the web application \nbut never becomes part of a query. By de\u0002nition, state parameters \ncannot result in SQL injection, and therefore, we only focus on in- \njectable parameters for our attacks. For example, in URL http:\/\/\nsome.host\/empldir\/Login.jsp?Login=john&Password= \nxyz&FormAction=login , for application Employee Directory, Lo-\ngin and Password are injectable parameters, whereas FormAction\nis a state parameter that the web application uses to decide how to\nhandle the user request. We did not consider all servlets in our study because some servlets\ncan only be accessed if the web session is in a very speci\u0002c state,\nwhich is dif\u0002cult to recreate automatically and would require cus- \ntom handling of each web application. We call accessible servlets\nthe servlets that, to be accessed, only required the user to be logged-\nin or did not require sessions at all. Because we were able to gener- \nate enough attacks considering accessible servlets only, we did not \nconsider the remaining servlets.\n6.2.2 Input Generation For our evaluation we generated a large set of inputs that rep-\nresented normal and malicious usage of the subject applications.\nThe attacks were developed by a Masters student at Georgia Tech\nwho worked for a local software-security company. The student\nwas an experienced programmer who had developed commercial- \nlevel penetration tools for detecting SQL-injection vulnerabilities. \nMoreover, the student was not familiar with our technique, which\nreduced the risk of developing a set of attacks biased by the knowl- \nedge of the approach and its capabilities. In the rest of this section, \nwe outline the speci\u0002c steps that were taken in order to generate the\nset of inputs and prepare them for usage in our evaluation. First , we identi\u0002ed all the servlets in each subject. Each servlet\nis a URL that accepts a set of parameters and that is typically ac-\ncessed via the submission of a web form. For example, in the lo- \ngin page of the example in Figure 1, the servlet is http:\/\/foo.\ncom\/show.jsp , and a generic access to the entry point is http:\n\/\/foo.com\/show.jsp?login= hvalue1 i&pass= hvalue2 i.\nFor the accessible servlets, we identi\u0002ed the corresponding injectable \nand state parameters. This step was necessary because if state pa-\nrameters are not assigned the correct value, the web application\nsimply returns an error, and no attack can be successful. Further, \nwe classi\u0002ed the type of each parameter as either string or numeric \nand identi\u0002ed the speci\u0002c values that could be used for the state\nparameters. (This part of the evaluation was performed manually \nand involved a considerable effort.) At the end of this \u0002rst phase, \nwe had two lists of parameters, state and injectable, for each appli-\ncation and servlet; each state parameter was associated with a set \nof possible values and each injectable parameter was classi\u0002ed as \neither string or numeric. Second , the student generated a set of attack strings, malicious\ninput strings that can be used to perform SQLIAs. To de\u0002ne the set\nof attack strings, the student used exploits that were developed by\ncommercial penetration teams to take advantage of SQL-injection vulnerabilities. The student also surveyed various sources that in-\ncluded US-CERT (\nhttp:\/\/www.us- cert.gov\/ ), CERT\/CC\nAdvisories ( http:\/\/www.cert.org\/advisories\/ ), and sev-\neral security-related mailing lists. The student used the examples\nof attacks discussed on those sites and mailing lists to de\u0002ne the\nattack strings. In this way, the student generated attack strings \nthat are representative of real attacks that could be performed on \nthe considered subjects. The set contained a total of 30 attack\nstrings that encoded a wide variety of attacks. The attack strings \nthemselves were each unique and represented a different way to \nexploit an SQLIA vulnerability. Most of the attack strings had\nbeen previously reported in literature [1]. These strings included \nattacks based on injections of additional statements, exploiting un- \ntyped parameters, stored procedures, tautologies, alternate encod-\nings, and injections of \u00e2\u0080\u009dUNION SELECT\u00e2\u0080\u009d, \u00e2\u0080\u009dORDER BY\u00e2\u0080\u009d, \u00e2\u0080\u009dHAV-\nING\u00e2\u0080\u009d and \u00e2\u0080\u009dJOIN\u00e2\u0080\u009d clauses. Other types of attacks, such as the ones \nthat leverage overly descriptive error messages and the ones based \non second-order injections were not included since they depended\non an initial \u0002rst round of successful injection. Third , the student generated two sets of inputs for each applica-\ntion. Each input consisted of the URL for a servlet together with\nthe value(s) of one or more parameters of that servlet. The \u0002rst \nset is the set of legitimate inputs, which we call LEGIT, and con- \ntains only inputs with legitimate parameters (i.e., inputs that cannot\nresult in an SQLIA). The second set is the set of SQL-injection \ninputs, which we call ATTACK, and consists of inputs such that \nat least one of the parameters is an attack string (i.e., inputs that\nmay result in an SQLIA). To populate set LEGIT, the student cre-\nated different inputs by using different combinations of legitimate \nvalues for the injectable parameters based on their type. All state \nparameters were always assigned a meaningful and correct value.\nFor each application, the LEGIT set contained 500 elements.\nTo populate the ATTACK sets, the student used two kinds of in-\nputs: (1) inputs for which one parameter is assigned an attack string\n(and all other parameters are assigned legitimate values); (2) inputs \nfor which more than one parameter is assigned an attack string. The \nstudent created inputs of the \u0002rst type by exhaustively assigning to\neach parameter of each servlet all possible attack strings, one at a \ntime. The remaining parameters were assigned various combina- \ntions of legitimate values based on their type. Then, all unsuccess-\nful attacks were eliminated from the set, that is, all attacks that were\nblocked by the web application were removed from the ATTACK \nset. (Some of the web applications performed suf\u0002cient input val- \nidation and returned an error page when they detected improper\ninput.) The student generated inputs of the second type for a web \napplication by randomly selecting, without repetition, an accessi- \nble servlet within the application and a set of possible values for all\nthe parameters. For each parameter, a random number between 1 \nand 60 was generated. If the number was less then or equal to 30, \nthe student assigned the corresponding attack string to the parame-\nter. Otherwise, he assigned a legitimate value to the parameter. In \nthis way, each parameter had a 50% chance of containing an attack \nstring. The student continued generating inputs of the second type  \n 181\n\nuntil we had either 100 successful attacks (i.e., attacks that were \nnot blocked by the web application and reached the database) or\n2,000 unsuccessful attacks. (Note that the random generation was\nalways able to generate at least 100 successful attacks, so we never \nreached the threshold of unsuccessful attacks.) For each applica- \ntion in the evaluation we had an ATTACK set whose size ranged\nfrom 140 to 280 elements. Table 2, explained in the next section, \nshows the number of attacks for each application. In the table, we \nalso report the number of unsuccessful attacks for completeness. \n6.3 Study 1: EffectivenessIn the \u0002rst study, we investigated RQ1, the effectiveness of our\ntechnique in detecting and preventing SQLIAs. We analyzed and \ninstrumented each application using AM NE S I A and ran all of the \ninputs in each of the applications' ATTACK sets. For each applica-\ntion, we measured the percentage of attacks detected and reported\nby AM NE S I A. (As previously discussed, when AM NE S I A de- \ntects an attack, it throws an exception, which is in turn returned by \nthe web application. Therefore, it is easy to accurately detect when\nan attack has been caught.)\nThe results for this study are shown in Table 2. The table shows\nfor each subject the number of unsuccessful attacks ( Unsuccess-\nful ), the number of successful attacks ( Successful), and the number\nof attacks detected and reported by AM NE S I A ( Detected), both\nin absolute terms and as a percentage over the total number of suc-\ncessful attacks, in parentheses. As the table shows, AM NE S I A \nachieved a perfect score. For all subjects, it was able to correctly \nidentify all attacks as SQLIAs, that is, it generated no false nega-\ntives.\nSubjectUnsuccessfulSuccessfulDetectedCheckers1195248248 (100%)Of\u0002ce Talk598160160 (100%)Employee Directory413280280 (100%)Bookstore1028182182 (100%)Events875260260 (100%)Classi\u0002eds823200200 (100%)Portal880140140 (100%)\nTable 2: Results of Study 1.\n6.4 Study 2: Ef\u0002ciency and Precision In the second study, we investigated RQ2andRQ3 . To inves-\ntigate RQ2(i.e., the ef\u0002ciency of our technique), we ran all of the\nlegitimate inputs in the LEGIT sets on the original (i.e., not instru- \nmented) web applications and measured the response time of the \napplications for each web request. We then ran the same inputs \non the versions of the web applications instrumented by AM NE - S I A and again measured the response time. Finally, we computed\nthe differences between the response times in the two cases, which \ncorresponds to the overhead imposed by our technique. We found that the overhead imposed by our technique is negligi-\nble and, in fact, barely measurable, ranging from 10 to 40 millisec-\nonds. This amount of time should be considered an upper bound \non the overhead, as our implementation was not written to be ef-\n\u0002cient. For example, we accessed \u0002le IO each time we checked \na query, both to load the model and to log the results. In a more \nperformance oriented implementation, these IO accesses would be\nminimized and cached to improve performance. The overhead re- \nsults con\u0002rm our expectations. Intuitively, the time for the network \naccess and the database transaction completely dominates the time\nrequired for the runtime checking. As the results show, our tech- nique is ef\u0002cient and can be used without affecting the response\ntime of a web application in a meaningful manner.\nTo investigate RQ3(i.e., the rate of false positives generated by\nour technique), we simply assessed whether AM NE S I A identi\u0002ed \nany legitimate query as an attack. The results of the assessment \nwere that AM NE S I A correctly identi\u0002ed all such queries as legit-\nimate queries and reported no false positives. \n6.5 Discussion\nThe results of our study are fairly clear cut. For all subjects,\nour technique was able to correctly identify all attacks as SQLIAs, \nwhile allowing all legitimate queries to be performed. In other \nwords, for the cases considered, our technique generated no false \npositives and no false negatives. The lack of false positives and\nfalse negatives is very promising and provides evidence of the via- \nbility of the technique. In our study, we did not compare our results with alternative\napproaches against SQLIAs because many of the automated ap-\nproaches that we are aware of, only address a small subset of the \npossible SQLIAs. (For example, the approach in [8] is focused on\ntype safety, and the one in [26] focuses only on tautologies.) There- \nfore, we know analytically that such approaches would not be able \nto identify many of the attacks in our test bed.\nAs for all empirical studies, there are some threats to the valid-\nity of our evaluation, mostly with respect to external validity. The \nresults of our study may be related to the speci\u0002c subjects consid- \nered and may not generalize to other web applications. To mini-\nmize this risk, we used a set of real web applications (except for \nthe two applications developed by students teams) and an extensive \nset of realistic attacks. Although more experimentation is needed\nbefore drawing de\u0002nitive conclusions on the effectiveness of the \ntechnique, the results we obtained so far are promising. \n7. CONCLUSION AND FUTURE WORK\nWe presented a new fully automated technique for detecting, pre-\nventing, and reporting SQL Injection Attacks (SQLIAs). The tech- \nnique is based on the intuition that the web-application code im-\nplicitly contains a \u00e2\u0080\u009cpolicy\u00e2\u0080\u009d that allows for distinguishing legitimate \nand malicious queries. To extract and check this policy, the tech- \nnique combines static and dynamic analysis. In the static phase,\nthe technique uses an existing string analysis to extract from the \nweb-application's code a model of all the query strings that could \nbe generated by the application. In the dynamic phase, the tech-\nnique monitors dynamically-created queries for conformance with \nthe statically-built model. Queries that are not compliant with the \nmodel are identi\u0002ed as SQLIAs, blocked, and relevant information\nis reported to developers and administrators. In this paper, we also presented AM NE S I A, a prototype tool\nthat implements our technique for Java-based web applications, and\nan empirical evaluation of the technique. The empirical evaluation\nof the technique was performed on a set of seven web applications \nthat consisted of two applications developed by a student team, but \nalso used by other researchers, and \u0002ve real applications. AM -\nNE S I A was able to stop all of the 1,470 attacks that we performed\non the considered applications without producing any false positive\nfor the 3,500 legitimate accesses to the applications. Furthermore, AM NE S I A proved to be quite ef\u0002cient in practice, at least for the\ncases considered\u00e2\u0080\u0094the overhead imposed by the technique on the\nweb application was barely measurable. In our future work we will investigate alternate techniques for\nbuilding SQL models for cases in which the static analysis cannot\nbe used (e.g., because of scalability issues). In particular, we will\nstudy possible alternative static analysis techniques. In our cur-  \n 182\n\nrent approach, we use a very precise (and expensive) analysis [5] to\nbuild the character-level model that we then compact and transform \ninto our SQL-query model. Our technique is mostly interested in\nSQL keywords and operators, and the strings representing them are \ntypically constant strings that are rarely manipulated in the appli- \ncation. Therefore, we may be able to use a simpli\u0002ed string analy-\nsis to extract the SQL-query models that our monitoring technique \nneeds directly from a suitable representation of the code. Finally, \nwe will investigate combined static and dynamic approaches for\nbuilding models to handle cases in which the static analysis can be \nsuccessfully applied on only a subset of the application. \nAcknowledgments \nThis work was supported in part by NSF awards CCR-0306372, \nCCR-0205422, and CCR-0209322. Wenke Lee and David Dagon \nprovided useful comments on an early version of the paper. Carl\nGould, Zhendong Su, and Premkumar Devanbu provided us with \nan implementation of their J DB C C H E C K E Rtool and with the set\nof subjects they used in their experimentation. Gary Wassermann \nprovided useful feedback and comments on our drafts. Jeremy Vie- \ngas helped to develop our test bed infrastructure and devoted long \nhours to the generation of the input data for our experiment. \n8. REFERENCES\n[1] C. Anley Advanced SQL Injection In SQL Server Applicatio ns.\nNext Generation Security Software Ltd. White Paper, 2002.\n[2] D. Aucsmith. Creating and maintaining software that resis ts\nmalicious attack. \nhttp:\/\/www.gtisc.gatech.edu\/aucsmith\nbio.htm\nDistinguished Lecture Series. Atlanta, GA. September 2004.\n[3] S. W. Boyd and A. D. Keromytis. SQLrand: Preventing SQL injection attacks. In Proceedings of the 2nd Applied Cryptography\nand Network Security (ACNS) Conference , pages 292\u00e2\u0080\u0093302, June\n2004.\n[4] A. Chawla and A. Orso. A generic instrumentation framework for\ncollecting dynamic information. In Online Proceeding of the ISSTA\nWorkshop on Empirical Research in Software Testing (WERST \n2004) , Boston, MA, USA, July 2004.\nhttp:\/\/www.sce.carleton.ca\/squall\/WERST2004 .\n[5] A. S. Christensen, A. M\u00c3\u00b8ller, and M. I. Schwartzbach. Pre cise\nAnalysis of String Expressions. In Proceedings of the 10th\nInternational Static Analysis Symposium, SAS 03 , volume 2694 of\nLNCS , pages 1\u00e2\u0080\u009318. Springer-Verlag, June 2003.\n[6] W. R. Cook and S. Rai. Safe Query Objects: Statically Type d\nObjects as Remotely Executable Queries. In Proceedings of the 27th\nInternational Conference on Software Engineering (ICSE 20 05),\n2005.\n[7] C. Gould, Z. Su, and P. Devanbu. JDBC Checker: A Static Ana lysis\nTool for SQL\/JDBC Applications. In Proceedings of the 26th\nInternational Conference on Software Engineering (ICSE 20 04) \u00e2\u0080\u0093\nFormal Demos , pages 697\u00e2\u0080\u0093698, 2004.\n[8] C. Gould, Z. Su, and P. Devanbu. Static Checking of Dynamic ally\nGenerated Queries in Database Applications. In Proceedings of the\n26th International Conference on Software Engineering (IC SE\n2004) , pages 645\u00e2\u0080\u0093654, 2004.\n[9] A. R. Group. Java Architecture for Bytecode Analysis (JA BA),\n2004. http:\n\/\/www.cc.gatech.edu\/aristotle\/Tools\/jaba.html .[10] W. G. Halfond and A. Orso. Combining Static Analysis and R\nuntime\nMonitoring to Counter SQL-Injection Attacks. In Proceeding of the\nThird International ICSE Workshop on Dynamic Analysis (WOD A\n2005) , St. Louis, MO, USA. May 2005.\n[11] M. Howard and D. LeBlanc. Writing Secure Code. Microsoft Press,\nRedmond, Washington, 2nd edition, 2003.\n[12] Y.-W. Huang, S.-K. Huang, T.-P. Lin, and C.-H. Tsai. Web Application Security Assessment by Fault Injection and Beha vior\nMonitoring. In Proceedings of the 11th International World Wide\nWeb Conference (WWW 2003) , May 2003.\n[13] Y.-W. Huang, F. Yu, C. Hang, C.-H. Tsai, D. T. Lee, and S.- Y. Kuo.\nSecuring Web Application Code by Static Analysis and Runtime \nProtection. In Proceedings of the 12th International World Wide Web\nConference (WWW 2004) , May 2004.\n[14] G. S. Kc, A. D. Keromytis, and V. Prevelakis. Countering Code-Injection Attacks with Instruction-Set Randomizatio n. In\nProceedings of the ACM Conference on Computer and\nCommunications Security (CCS 2003) , pages 272\u00e2\u0080\u0093280, October\n2003.\n[15] V. B. Livshits and M. S. Lam. Finding Security Vulnerabil ities in\nJava Applications with Static Analysis In Usenix Security\nSymposium , Aug. 2005.\n[16] O. Maor and A. Shulman. SQL Injection Signatures Evasion .\nhttp:\/\/www.imperva.com\/\napplication\ndefensecenter\/whitepapers\/\nsqlinjectionsignaturesevasion.html , April 2004.\nWhite paper.\n[17] M. Martin, V. B. Livshits, and M. S. Lam. Finding applicat ion errors\nusing PQL: a program query language. In Proceedings of the ACM\nConference on Object-Oriented Programming, Systems, Lang uages,\nand Applications (OOPSLA), Oct. 2005.\n[18] R. McClure and I. Kr \u00c2\u00a8\nuger. SQL DOM: Compile Time Checking of\nDynamic SQL Statements. In Proceedings of the 27th International\nConference on Software Engineering (ICSE 2005) , pages 88\u00e2\u0080\u009396,\n2005.\n[19] S. McDonald. SQL Injection: Modes of attack, defense, a nd why it\nmatters. \nhttp:\/\/www.governmentsecurity.org\/articles\/ \nSQLInjectionModesofAttackDefenceandWhyItMatters.\nphp , April 2004. White paper.\n[20] Anh Nguyen-Tuong, Salvatore Guarnieri, Doug Greene, J eff Shirley,\nDavid Evans. Automatically Hardening Web Applications Usin g\nPrecise Tainting Information In Twentieth IFIP International\nInformation Security Conference (SEC 2005) , May 2005.\n[21] OWASPD \u00e2\u0080\u0093 Open Web Application Security Project. Top ten most\ncritical web application vulnerabilities. http:\n\/\/www.owasp.org\/documentation\/topten.html , 2005.\n[22] T. Pietraszek1 and C. V. Berghe. Defending Against Inje ction\nAttacks through Context-Sensitive String Evaluation. In Proceedings\nof Recent Advances in Intrusion Detection (RAID2005) , 2005.\n[23] D. Scott and R. Sharp. Abstracting Application-level W eb Security.\nIn Proceedings of the 11th International Conference on the Wor ld\nWide Web (WWW 2002) , pages 396\u00e2\u0080\u0093407, 2002.\n[24] SecuriTeam. SQL Injection Walkthrough. http:\/\/www.securiteam.com\/securityreviews\/\n5DP0N1P76E.html , May 2002. White paper.\n[25] F. Valeur and D. Mutz and G. Vigna A Learning-Based Appro ach to\nthe Detection of SQL Attacks In Proceedings of the Conference on\nDetection of Intrusions and Malware Vulnerability Assessm ent\n(DIMVA), July 2005.\n[26] G. Wassermann and Z. Su. An Analysis Framework for Securit y in\nWeb Applications. In Proceedings of the FSE Workshop on\nSpeci\u0002cation and Veri\u0002cation of Component-Based Systems\n(SAVCBS 2004) , pages 70\u00e2\u0080\u009378, 2004.  \n 183"}]